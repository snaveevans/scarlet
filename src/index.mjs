import { parseArgs } from 'node:util';
import path from 'node:path';
import fs from 'node:fs';
import os from 'node:os';
import crypto from 'node:crypto';
import { loadConfig } from './config/index.mjs';
import { createLogger } from './logger/index.mjs';
import { createStateManager } from './state/index.mjs';
import { detectPrdChanges } from './detector/index.mjs';
import { planFromPrd } from './planner/index.mjs';
import { execute } from './executor/index.mjs';
import * as gitOps from './git-ops/index.mjs';
import { containsLikelySecret, redactSensitive, truncateForReport } from './redaction/index.mjs';

class ProcessingError extends Error {
  constructor(stage, message, logs = '') {
    super(message);
    this.stage = stage;
    this.logs = logs;
  }
}

const { values: args } = parseArgs({
  options: {
    config: { type: 'string', short: 'c' },
    once: { type: 'boolean', default: false },
  },
});

if (!args.config) {
  console.error('Usage: node src/index.mjs --config <path>');
  process.exit(1);
}

function normalizeBranchPrefix(prefix) {
  if (prefix.endsWith('/')) return prefix;
  return `${prefix}/`;
}

function shortHash(input, length = 10) {
  return crypto.createHash('sha256').update(String(input)).digest('hex').slice(0, length);
}

function resolveConfiguredPath(repoPath, configuredPath) {
  if (!configuredPath) return undefined;
  return path.isAbsolute(configuredPath)
    ? configuredPath
    : path.resolve(repoPath, configuredPath);
}

function parseRemoteOwnerRepo(remoteUrl) {
  const remote = String(remoteUrl ?? '').trim();
  const match = remote.match(/[:/]([^/]+)\/([^/.]+?)(?:\.git)?$/);
  if (!match) return null;
  const [, owner, repo] = match;
  return { owner, repo };
}

function buildFeatureBranchName(branchPrefix, branchSlug, contentHash) {
  const prefix = normalizeBranchPrefix(branchPrefix);
  const safeSlug = branchSlug || 'prd-change';
  const suffix = contentHash.slice(0, 8);
  return `${prefix}${safeSlug}-${suffix}`;
}

function buildFailureBranchName(branchPrefix, filePath) {
  const prefix = normalizeBranchPrefix(branchPrefix);
  return `${prefix}failure-${shortHash(filePath)}`;
}

function buildFailureReportPath(filePath, branchSlug) {
  return path.posix.join('docs', 'scarlet', 'failures', `${shortHash(filePath)}-${branchSlug}.md`);
}

function composeFailureReport({
  filePath,
  title,
  stage,
  message,
  branchName,
  mainBranch,
  reportAt,
  logs,
}) {
  return [
    `# Scarlet Failure Report: ${title}`,
    '',
    '## Context',
    `- PRD: \`${filePath}\``,
    `- Stage: \`${stage}\``,
    `- Branch: \`${branchName}\``,
    `- Base branch: \`${mainBranch}\``,
    `- Reported at: \`${reportAt}\``,
    '',
    '## Error',
    '',
    message,
    '',
    '## Redacted Logs (excerpt)',
    '',
    '```text',
    logs || '(no logs provided)',
    '```',
    '',
    '_Generated by Scarlet autonomous error reporting._',
  ].join('\n');
}

function composeFailurePrBody({
  filePath,
  mainBranch,
  implementationBranch,
  failureBranch,
  stage,
  reportPath,
}) {
  return [
    '## Summary',
    `- Scarlet failed while processing \`${filePath}\``,
    `- Failure stage: \`${stage}\``,
    `- Implementation branch: \`${implementationBranch}\``,
    `- Failure report branch: \`${failureBranch}\``,
    `- Base branch: \`${mainBranch}\``,
    '',
    '## Details',
    `- See \`${reportPath}\` for redacted logs and current status.`,
  ].join('\n');
}

async function upsertPullRequest({ owner, repo, head, base, title, body, token }) {
  const existing = await gitOps.findOpenPullRequest({ owner, repo, head, base, token });
  if (existing) {
    return gitOps.updatePullRequest({ owner, repo, number: existing.number, title, body, token });
  }
  return gitOps.createPullRequest({ owner, repo, head, base, title, body, token });
}

async function closePullRequestIfOpen({ owner, repo, head, base, token }) {
  const existing = await gitOps.findOpenPullRequest({ owner, repo, head, base, token });
  if (!existing) return null;
  return gitOps.updatePullRequest({ owner, repo, number: existing.number, state: 'closed', token });
}

const config = loadConfig(args.config);
const logger = createLogger({
  level: config.logging.level,
  file: resolveConfiguredPath(config.targetRepo.localPath, config.logging.file),
});

const statePath = resolveConfiguredPath(config.targetRepo.localPath, config.state.path);
const stateManager = createStateManager(statePath);

const usesRepoLocalScarletPaths = [config.state.path, config.logging.file]
  .filter(Boolean)
  .some(value => !path.isAbsolute(value) && value.includes('.scarlet/'));

if (usesRepoLocalScarletPaths) {
  const gitignorePath = path.join(config.targetRepo.localPath, '.gitignore');
  try {
    const existing = fs.existsSync(gitignorePath) ? fs.readFileSync(gitignorePath, 'utf-8') : '';
    if (!existing.includes('.scarlet/')) {
      fs.appendFileSync(gitignorePath, '\n.scarlet/\n');
    }
  } catch {
    // best effort
  }
}

let running = true;
process.on('SIGINT', () => { running = false; });
process.on('SIGTERM', () => { running = false; });

async function publishFailurePr({
  cwd,
  owner,
  repo,
  filePath,
  title,
  branchSlug,
  featureBranchName,
  stage,
  message,
  redactedLogs,
  mainBranch,
}) {
  const failureBranchName = buildFailureBranchName(config.git.branchPrefix, filePath);
  const reportPath = buildFailureReportPath(filePath, branchSlug);
  const reportAt = new Date().toISOString();
  const report = composeFailureReport({
    filePath,
    title,
    stage,
    message,
    branchName: featureBranchName,
    mainBranch,
    reportAt,
    logs: redactedLogs,
  });

  const tempWorktree = fs.mkdtempSync(path.join(os.tmpdir(), 'scarlet-failure-'));

  try {
    await gitOps.addDetachedWorktree(cwd, tempWorktree, `origin/${mainBranch}`);

    const hasRemoteFailureBranch = await gitOps.branchExistsRemote(tempWorktree, 'origin', failureBranchName);
    const startPoint = hasRemoteFailureBranch
      ? `origin/${failureBranchName}`
      : `origin/${mainBranch}`;
    await gitOps.createBranch(tempWorktree, failureBranchName, startPoint);

    const fullReportPath = path.join(tempWorktree, reportPath);
    fs.mkdirSync(path.dirname(fullReportPath), { recursive: true });
    fs.writeFileSync(fullReportPath, `${report}\n`);

    await gitOps.stagePaths(tempWorktree, [reportPath]);
    await gitOps.commit(tempWorktree, `chore: report failure for ${title}`, config.git.commitAuthor);
    await gitOps.push(tempWorktree, 'origin', failureBranchName);

    const prTitle = `chore: failure report for ${title}`;
    const prBody = composeFailurePrBody({
      filePath,
      mainBranch,
      implementationBranch: featureBranchName,
      failureBranch: failureBranchName,
      stage,
      reportPath,
    });

    const pr = await upsertPullRequest({
      owner,
      repo,
      head: failureBranchName,
      base: mainBranch,
      title: prTitle,
      body: prBody,
      token: config.git.githubToken,
    });

    logger.info(`Failure PR upserted: ${pr.url}`);
    return pr.url;
  } finally {
    await gitOps.removeWorktree(cwd, tempWorktree).catch(() => {});
    fs.rmSync(tempWorktree, { recursive: true, force: true });
  }
}

async function recordFailure({
  state,
  filePath,
  contentHash,
  fullBranchName,
  stage,
  message,
  logs,
  remote,
  plan,
  mainBranch,
  cwd,
}) {
  const redactedLogs = truncateForReport(redactSensitive(logs), 8192);
  const redactedMessage = redactSensitive(message);
  let failurePrUrl = null;

  if (config.git.createPr) {
    if (!config.git.githubToken) {
      logger.error('createPr is enabled but githubToken is missing; cannot publish failure PR');
    } else if (!remote) {
      logger.error('createPr is enabled but remoteUrl is missing/invalid; cannot publish failure PR');
    } else {
      try {
        failurePrUrl = await publishFailurePr({
          cwd,
          owner: remote.owner,
          repo: remote.repo,
          filePath,
          title: plan.title,
          branchSlug: plan.branchName,
          featureBranchName: fullBranchName,
          stage,
          message: redactedMessage,
          redactedLogs,
          mainBranch,
        });
      } catch (err) {
        logger.error('Failed to publish failure PR', { error: err.message, filePath, stage });
      }
    }
  }

  state.processedPrds[filePath] = {
    status: 'failed',
    branchName: fullBranchName,
    contentHash,
    processedAt: new Date().toISOString(),
    errorStage: stage,
    error: redactedMessage,
    logsExcerpt: truncateForReport(redactedLogs, 2048),
    failurePrUrl,
  };
  stateManager.save(state);
}

async function closeFailurePrIfNeeded({ remote, filePath, mainBranch }) {
  if (!remote || !config.git.createPr || !config.git.githubToken) return;
  const failureBranchName = buildFailureBranchName(config.git.branchPrefix, filePath);
  try {
    const closed = await closePullRequestIfOpen({
      owner: remote.owner,
      repo: remote.repo,
      head: failureBranchName,
      base: mainBranch,
      token: config.git.githubToken,
    });
    if (closed) {
      logger.info(`Closed failure PR: ${closed.url}`);
    }
  } catch (err) {
    logger.warn('Unable to close failure PR after successful run', {
      filePath,
      error: err.message,
    });
  }
}

async function pollCycle() {
  const cwd = config.targetRepo.localPath;
  const mainBranch = config.targetRepo.mainBranch;
  const remote = parseRemoteOwnerRepo(config.targetRepo.remoteUrl);

  logger.info('Starting poll cycle');

  try {
    await gitOps.fetch(cwd);
  } catch (err) {
    logger.warn('Fetch failed, skipping cycle', { error: err.message });
    return;
  }

  let remoteHead;
  try {
    remoteHead = await gitOps.revParse(cwd, `origin/${mainBranch}`);
  } catch (err) {
    logger.error('Failed to resolve remote HEAD', { error: err.message });
    return;
  }

  const state = stateManager.load();
  const fromCommit = state.lastProcessedCommit;

  if (fromCommit === remoteHead) {
    logger.info('No new commits');
    return;
  }

  let changes;
  try {
    changes = await detectPrdChanges({
      cwd,
      fromCommit,
      toCommit: remoteHead,
      prdGlob: config.targetRepo.prdGlob,
      stateManager,
    });
  } catch (err) {
    logger.error('Detection failed', { error: err.message });
    return;
  }

  if (changes.length === 0) {
    logger.info('No PRD changes detected');
    state.lastProcessedCommit = remoteHead;
    stateManager.save(state);
    return;
  }

  logger.info(`Found ${changes.length} PRD change(s)`);

  let cycleHadFailures = false;

  for (const change of changes) {
    const { filePath, content, contentHash } = change;
    const plan = planFromPrd(content, filePath);
    const fullBranchName = buildFeatureBranchName(config.git.branchPrefix, plan.branchName, contentHash);

    logger.info(`Processing PRD: ${filePath}`);

    try {
      const preflightStatus = await gitOps.statusPorcelain(cwd);
      if (preflightStatus.length > 0) {
        throw new ProcessingError(
          'preflight',
          'Target repository has uncommitted changes; refusing to process autonomously',
          preflightStatus.join('\n')
        );
      }

      await gitOps.checkout(cwd, mainBranch);
      try {
        await gitOps.checkout(cwd, `origin/${mainBranch}`);
      } catch {
        // detached HEAD is acceptable while syncing with remote
      }
      await gitOps.checkout(cwd, mainBranch);

      try {
        await gitOps.createBranch(cwd, fullBranchName, `origin/${mainBranch}`);
      } catch {
        await gitOps.checkout(cwd, fullBranchName);
      }

      const result = await execute({
        agentType: config.agent.type,
        workingDirectory: cwd,
        instructions: plan.instructions,
        branchName: plan.branchName,
        timeout: config.agent.timeout,
        command: config.agent.command,
      });

      if (!result.success) {
        throw new ProcessingError('agent', `Agent execution failed for ${filePath}`, result.logs);
      }
      if (!result.filesChanged || result.filesChanged.length === 0) {
        throw new ProcessingError('agent', 'Agent completed but reported no changed files', result.logs);
      }

      await gitOps.stagePaths(cwd, result.filesChanged);

      const stagedDiff = await gitOps.stagedDiff(cwd);
      if (!stagedDiff.trim()) {
        throw new ProcessingError('commit', 'No staged changes found after filtering agent output');
      }

      if (containsLikelySecret(stagedDiff)) {
        throw new ProcessingError(
          'commit',
          'Blocked commit because staged changes appear to contain secrets',
          stagedDiff
        );
      }

      await gitOps.commit(cwd, `feat: implement ${plan.title}`, config.git.commitAuthor);

      try {
        await gitOps.push(cwd, 'origin', fullBranchName);
      } catch (err) {
        throw new ProcessingError('push', `Push failed: ${err.message}`);
      }

      let prUrl = null;
      if (config.git.createPr) {
        if (!config.git.githubToken) {
          throw new ProcessingError('pr-create', 'createPr is enabled but githubToken is missing');
        }
        if (!remote) {
          throw new ProcessingError('pr-create', 'createPr is enabled but targetRepo.remoteUrl is missing/invalid');
        }

        try {
          const pr = await upsertPullRequest({
            owner: remote.owner,
            repo: remote.repo,
            head: fullBranchName,
            base: mainBranch,
            title: `feat: ${plan.title}`,
            body: `Implements PRD: \`${filePath}\`\n\nGenerated by Scarlet.`,
            token: config.git.githubToken,
          });
          prUrl = pr.url;
          logger.info(`PR upserted: ${prUrl}`);
        } catch (err) {
          throw new ProcessingError('pr-create', `PR creation/update failed: ${err.message}`);
        }
      }

      state.processedPrds[filePath] = {
        status: 'completed',
        branchName: fullBranchName,
        prUrl,
        contentHash,
        processedAt: new Date().toISOString(),
      };
      stateManager.save(state);

      await closeFailurePrIfNeeded({ remote, filePath, mainBranch });

      await gitOps.checkout(cwd, mainBranch);
      logger.info(`Completed PRD: ${filePath}`);
    } catch (err) {
      cycleHadFailures = true;

      const stage = err.stage ?? 'unknown';
      const message = err.message ?? 'Unknown processing error';
      const logs = err.logs ?? '';

      logger.error(`Failed processing ${filePath}`, {
        stage,
        error: redactSensitive(message),
      });

      await recordFailure({
        state,
        filePath,
        contentHash,
        fullBranchName,
        stage,
        message,
        logs,
        remote,
        plan,
        mainBranch,
        cwd,
      });

      await gitOps.checkout(cwd, mainBranch).catch(() => {});
    }
  }

  if (cycleHadFailures) {
    logger.warn('One or more PRDs failed; keeping lastProcessedCommit unchanged for retry');
    return;
  }

  state.lastProcessedCommit = remoteHead;
  stateManager.save(state);
}

async function main() {
  logger.info('Scarlet starting', { config: args.config });

  if (args.once) {
    await pollCycle();
    logger.info('Single run complete');
    logger.close();
    return;
  }

  while (running) {
    try {
      await pollCycle();
    } catch (err) {
      logger.error('Unexpected error in poll cycle', { error: err.message });
    }

    const waitMs = config.polling.intervalSeconds * 1000;
    await new Promise(resolve => {
      const timer = setTimeout(resolve, waitMs);
      const check = setInterval(() => {
        if (!running) {
          clearTimeout(timer);
          clearInterval(check);
          resolve();
        }
      }, 500);
    });
  }

  logger.info('Scarlet shutting down');
  logger.close();
}

main().catch(err => {
  console.error('Fatal error:', err);
  process.exit(1);
});
